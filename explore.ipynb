{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata\n",
    "import pandas as pd\n",
    "import nltk\n",
    "\n",
    "\n",
    "from nltk.corpus import words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf=pd.read_pickle('cleanpickle.pkl')\n",
    "datadf\n",
    "\n",
    "\n",
    "df_C=datadf[datadf['language']=='C']\n",
    "df_Py=datadf[datadf['language']=='Python']\n",
    "df_Java=datadf[datadf['language']=='Java']\n",
    "\n",
    "# Seperating to find independent word sets\n",
    "importantcols=['language', 'repo', 'stemmed']\n",
    "#Next we isolate the impoortant cols\n",
    "\n",
    "df_C=df_C[importantcols]\n",
    "df_Py=df_Py[importantcols]\n",
    "df_Java=df_Java[importantcols]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of unique \"words\" for each language is as follows:\n",
      "\n",
      "Python:\n",
      "0\n",
      "\n",
      "C:\n",
      "675\n",
      "\n",
      "Java:\n",
      "0\n",
      "\n",
      "The total number of unique \"words\" in the union of every language is as follows:\n",
      "2383\n",
      "\n",
      "The total number of unique \"words\" in the intersection of every language is as follows:\n",
      "1119\n"
     ]
    }
   ],
   "source": [
    "def wordset(df):\n",
    "    dflist=list(df['stemmed'])\n",
    "    dflist=' '.join(dflist)\n",
    "    dflist=dflist.split()\n",
    "    dflist=set(dflist)\n",
    "    return dflist\n",
    "\n",
    "c_wordset=wordset(df_C)\n",
    "\n",
    "py_wordset=wordset(df_Py)\n",
    "\n",
    "java_wordset=wordset(df_Java)\n",
    "\n",
    "wordsetslist=[c_wordset,py_wordset,java_wordset]\n",
    "\n",
    "\n",
    "setints=set()\n",
    "\n",
    "setints=c_wordset.intersection(*wordsetslist)\n",
    "setints\n",
    "\n",
    "\n",
    "unionset=set()\n",
    "\n",
    "unionset=unionset.union(*wordsetslist)\n",
    "unionset\n",
    "\n",
    "\n",
    "disjointfromaggunion=unionset-setints;disjointfromaggunion\n",
    "\n",
    "\n",
    "unique_C=c_wordset-(py_wordset.union(java_wordset));unique_C\n",
    "unique_Py=py_wordset-(c_wordset.union(java_wordset));unique_Py\n",
    "unique_Java=java_wordset-(c_wordset.union(py_wordset));unique_Java\n",
    "\n",
    "\n",
    "print(f'The total number of unique \"words\" for each language is as follows:\\n\\nPython:\\n{len(unique_Py)}\\n\\nC:\\n{len(unique_C)}\\n\\nJava:\\n{len(unique_Java)}')\n",
    "print()\n",
    "print(f'The total number of unique \"words\" in the union of every language is as follows:\\n{len(unionset)}')\n",
    "print()\n",
    "print(f'The total number of unique \"words\" in the intersection of every language is as follows:\\n{len(setints)}')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def wordslist(df):\n",
    "    dflist=list(df['stemmed'])\n",
    "    dflist=' '.join(dflist)\n",
    "    dflist=dflist.split()\n",
    "    return dflist\n",
    "\n",
    "def combinedwordlist(df_C,df_Py,df_Java):\n",
    "    combined=[]\n",
    "    c_wordlist=wordslist(df_C)\n",
    "    combined.extend(c_wordlist)\n",
    "\n",
    "    py_wordlist=wordslist(df_Py)\n",
    "    combined.extend(py_wordlist)\n",
    "\n",
    "    java_wordlist=wordslist(df_Java)\n",
    "    combined.extend(java_wordlist)\n",
    "    combined.sort()\n",
    "    return combined\n",
    "\n",
    "\n",
    "combined=combinedwordlist(df_C,df_Py,df_Java)\n",
    "\n",
    "\n",
    "def combinedwordcountdf(df_C,df_Py,df_Java):\n",
    "   combined=[]\n",
    "   c_wordlist=wordslist(df_C)  \n",
    "   py_wordlist=wordslist(df_Py)\n",
    "   java_wordlist=wordslist(df_Java)\n",
    "\n",
    "   c_wordlist.sort()\n",
    "   py_wordlist.sort()\n",
    "   java_wordlist.sort()\n",
    "\n",
    "   combined.extend(c_wordlist)   \n",
    "   combined.extend(py_wordlist)   \n",
    "   combined.extend(java_wordlist)\n",
    "   combined.sort()\n",
    "   serieslist=[combined,c_wordlist,py_wordlist,java_wordlist]\n",
    "   serieslist=[pd.Series(freq).value_counts() for freq in serieslist]\n",
    "   word_counts_df = (pd.concat(serieslist, axis=1, sort=True)\n",
    "               .set_axis(['all', 'c', 'py','java'], axis=1, inplace=False)\n",
    "               .fillna(0)\n",
    "               .apply(lambda s: s.astype(int)))\n",
    "   return word_counts_df\n",
    "\n",
    "\n",
    "word_counts_df=combinedwordcountdf(df_C,df_Py,df_Java)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "collist=word_counts_df.columns.to_list()\n",
    "popped=collist.pop(collist.index('all'))\n",
    "popped\n",
    "for i in collist:\n",
    "    word_counts_df[f'{i}_TF']=word_counts_df[i]/word_counts_df[popped]\n",
    "\n",
    "\n",
    "collist=word_counts_df.columns.to_list()\n",
    "collist.sort()\n",
    "word_counts_df=word_counts_df[collist]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment below for your first run to create the filter\n",
    "# total=list(set(combined))\n",
    "# total.sort()\n",
    "# total\n",
    "\n",
    "# total=list(filter(lambda x : x in  words.words(),total))\n",
    "# total=pd.to_pickle(pd.Series(total),'words.pkl')\n",
    "\n",
    "# total=pd.read_pickle('words.pkl')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method IndexOpsMixin.tolist of Index(['all', 'c', 'cfreq', 'java', 'javafreq', 'py', 'pyfreq'], dtype='object')>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_df['c','python','']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
