{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#pdf plumber\n",
    "#csv.preview\n",
    "import pandas as pd\n",
    "#import unicode character database\n",
    "import unicodedata\n",
    "#import regular expression operations\n",
    "import re\n",
    "\n",
    "#import natural language toolkit\n",
    "import nltk\n",
    "\n",
    "\n",
    "#import our aquire\n",
    "from acquire import *\n",
    "\n",
    "\n",
    "#import our stopwords list\n",
    "from nltk.corpus import stopwords\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "original = \"Paul Erdős and George Pólya were influential Hungarian mathematicians who contributed \\\n",
    "a lot to the field. Erdős's name contains the Hungarian letter 'ő' ('o' with double acute accent), \\\n",
    "but is often incorrectly written as Erdos or Erdös either by mistake or out of typographical necessity\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def split_apply_join(funct,listobj):\n",
    "    'helperfuction letters'\n",
    "\n",
    "    mapped=map(funct, listobj)\n",
    "    mapped=list(mapped)\n",
    "    mapped=''.join(mapped)\n",
    "  \n",
    "    return mapped\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def stopfilter(text,stop_words_extend_reduce=[\"'\"]):\n",
    "    'we use symmetric difference so if a is already in stop words then it will be added to our third set else our third set will be missing it'\n",
    "    #create oujr english stopwords list\n",
    "\n",
    "    stops = set(stopwords.words('english'))\n",
    "    stop_words_extend_reduce=set(stop_words_extend_reduce)\n",
    "    stops=stops.symmetric_difference(stop_words_extend_reduce)\n",
    "\n",
    "    # stops=(stops|stop_words_extend)-exclude_words\n",
    "    #another way\n",
    "    \n",
    "    filtered=list(filter((lambda x: x not in stops), text.split()))\n",
    "    filtered=' '.join(filtered)\n",
    "\n",
    "    return filtered\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def basic_clean(text,regexfilter=r'[^a-z0-9\\'\\s]'):\n",
    "    '''   \n",
    "    Filters out all special characters if you need to edit then supply a new regex filter \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #make a copy and begin to transform it\n",
    "    newtext = text.lower()\n",
    "\n",
    "    #encode into ascii then decode\n",
    "    newtext = unicodedata.normalize('NFKD', newtext)\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8')\n",
    "\n",
    "    #use re.sub to remove special characters\n",
    "    newtext = re.sub(fr'{regexfilter}', '', newtext)\n",
    "\n",
    "    return newtext\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "def tokenizer(text,regexfilter=r'[^a-z0-9\\'\\s]'):\n",
    "    ''' \n",
    "    For a large file just save it locally\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    newtext=basic_clean(text,regexfilter=regexfilter)\n",
    "    #make ready tokenizer object\n",
    "    tokenize = nltk.tokenize.ToktokTokenizer()\n",
    "    #use the tokenizer\n",
    "    newtext = tokenize.tokenize(newtext, return_str=True)\n",
    "    return newtext\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def stemmed(text,regexfilter=r'[^a-z0-9\\'\\s]'):\n",
    "    '''    \n",
    "    Takes text, tokenizes it, stems it\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "    #make ready porter stemmer object\n",
    "    newtext=tokenizer(text,regexfilter=regexfilter)\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stemmedlist=split_apply_join(ps.stem,newtext)\n",
    "    return stemmedlist\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def lemmatizor(text,regexfilter=r'[^a-z0-9\\'\\s]'):\n",
    "    '''    \n",
    "    \n",
    "      Takes text, tokenizes it, lemmatizes it\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    '''\n",
    "\n",
    "    #make ready the lemmatizer object\n",
    "    newtext=tokenizer(text,regexfilter=regexfilter)\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmatized=split_apply_join(wnl.lemmatize,newtext)\n",
    "    return lemmatized\n",
    "\n",
    "\n",
    "\n",
    "def dictlist_lemmatizor_else_stemmer(dictlistog,regexfilter=r'[^a-z0-9\\'\\s]',stop_words_extend_reduce=[\"'\"],lemmatize=True):\n",
    "    ''' \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        #   Stem or Lemmatize \n",
    "        # if file is large and resources are scarce stem otherwise you can expect better performace from lemmatize\n",
    "    '''\n",
    "    dictlist=deepcopy(dictlistog)\n",
    "    if lemmatize==True:\n",
    "        for i in range(0,len(dictlist)):\n",
    "            keys=dictlist[i].keys()\n",
    "            for k in keys:\n",
    "                text=dictlist[i].get(k)\n",
    "                lemmatized=lemmatizor(text,regexfilter)\n",
    "                stopfilteredlemitezed=stopfilter(lemmatized,stop_words_extend_reduce=stop_words_extend_reduce)\n",
    "                dictlist[i].update({k:stopfilteredlemitezed})\n",
    "    else:\n",
    "        for i in range(0,len(dictlist)):\n",
    "            keys=dictlist[i].keys()\n",
    "            for k in keys:\n",
    "                text=dictlist[i].get(k)\n",
    "                stem=stemmed(text,regexfilter)\n",
    "                stopfilteredstem=stopfilter(stem,stop_words_extend_reduce=stop_words_extend_reduce)\n",
    "                dictlist[i].update({k:stopfilteredstem})\n",
    "    return dictlist\n",
    "\n",
    "\n",
    "\n",
    "def dictlist_super_NLP_comp(dictlist,regexfilter=r'[^a-z0-9\\'\\s]',stop_words_extend_reduce=[\"'\"],interestingkeys=[]):\n",
    "    ''\n",
    "    ndictlist=deepcopy(dictlist)\n",
    "    for i in range(0,len(ndictlist)):            \n",
    "            \n",
    "            for a in range(0,len(interestingkeys)):\n",
    "                k=interestingkeys[a]\n",
    "                text=dictlist[i].get(k)\n",
    "                ndictlist[i].pop(k)\n",
    "                ndictlist[i].update({f'{k}_org':text})\n",
    "                clean=basic_clean(text,regexfilter=regexfilter)\n",
    "                ndictlist[i].update({f'{k}_cleaned':clean})\n",
    "                lemmatized=lemmatizor(text,regexfilter)\n",
    "                stopfilteredlemitezed=stopfilter(lemmatized,stop_words_extend_reduce=stop_words_extend_reduce)\n",
    "                ndictlist[i].update({f'{k}_lemmatized':stopfilteredlemitezed})\n",
    "                stem=stemmed(text,regexfilter)\n",
    "                stopfilteredstem=stopfilter(stem,stop_words_extend_reduce=stop_words_extend_reduce)\n",
    "                ndictlist[i].update({f'{k}_stemmed':stopfilteredstem})\n",
    "\n",
    "    \n",
    " \n",
    "                \n",
    "               \n",
    "\n",
    "    a=pd.DataFrame(ndictlist[0],columns=list(ndictlist[0].keys()),index=[0])\n",
    "    for i,s in enumerate(ndictlist):\n",
    "        b=pd.DataFrame(s,columns=list(s.keys()),index=[i])\n",
    "        a=pd.merge(a,b,how='outer',right_index=False,left_index=False)\n",
    "    df=a\n",
    "\n",
    "\n",
    "  \n",
    "       \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paul erdos and george polya were influential hungarian mathematicians who contributed a lot to the field erdos ' s name contains the hungarian letter ' o ' ' o ' with double acute accent but is often incorrectly written as erdos or erdos either by mistake or out of typographical necessity\n",
      "george polya influential hungarian mathematicians contributed a lot field name contains hungarian letter double acute accent often incorrectly written either mistake typographical necessity\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "lemmatized=lemmatizor(original,regexfilter=r'[^a-z0-9\\'\\s]')\n",
    "print(lemmatized)\n",
    "stopfilteredlemitezed=stopfilter(lemmatized,stop_words_extend_reduce=[\"'\",\"erdos\",\"paul\",\"a\"])\n",
    "print(stopfilteredlemitezed)\n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardmacken/codeup-data-science/natural-language-processing-exercises/acquire.py:42: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 42 of the file /Users/richardmacken/codeup-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = soupify(get(base_url).content)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "cat articles length:  12\n",
      "length of all_articles:  12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richardmacken/codeup-data-science/natural-language-processing-exercises/acquire.py:51: GuessedAtParserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 51 of the file /Users/richardmacken/codeup-data-science/natural-language-processing-exercises/acquire.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  cat_soup = soupify(get(cat_url).content)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "cat articles length:  25\n",
      "length of all_articles:  37\n",
      "<Response [200]>\n",
      "cat articles length:  25\n",
      "length of all_articles:  62\n",
      "<Response [200]>\n",
      "cat articles length:  25\n",
      "length of all_articles:  87\n",
      "<Response [200]>\n",
      "cat articles length:  24\n",
      "length of all_articles:  111\n",
      "<Response [200]>\n",
      "cat articles length:  25\n",
      "length of all_articles:  136\n",
      "<Response [200]>\n",
      "cat articles length:  25\n",
      "length of all_articles:  161\n",
      "<Response [200]>\n",
      "cat articles length:  25\n",
      "length of all_articles:  186\n",
      "<Response [200]>\n",
      "cat articles length:  25\n",
      "length of all_articles:  211\n",
      "<Response [200]>\n",
      "cat articles length:  25\n",
      "length of all_articles:  236\n",
      "<Response [200]>\n",
      "cat articles length:  25\n",
      "length of all_articles:  261\n",
      "<Response [200]>\n",
      "cat articles length:  24\n",
      "length of all_articles:  285\n"
     ]
    }
   ],
   "source": [
    "url = 'https://inshorts.com/en/read'\n",
    "arts = get_all_shorts(url)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_articles=deepcopy(arts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "stopped_lemma=dictlist_lemmatizor_else_stemmer(all_articles,regexfilter=r'[^a-z0-9\\'\\s]',stop_words_extend_reduce=[\"'\"],lemmatize=True)\n",
    "stopped_stemmed=dictlist_lemmatizor_else_stemmer(all_articles,regexfilter=r'[^a-z0-9\\'\\s]',stop_words_extend_reduce=[\"'\"],lemmatize=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>275</th>\n",
       "      <th>276</th>\n",
       "      <th>277</th>\n",
       "      <th>278</th>\n",
       "      <th>279</th>\n",
       "      <th>280</th>\n",
       "      <th>281</th>\n",
       "      <th>282</th>\n",
       "      <th>283</th>\n",
       "      <th>284</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>title</th>\n",
       "      <td>Nigerian weightlifter in dope net, India may gain</td>\n",
       "      <td>Samsung launches Galaxy Star 2 Plus at Rs.7,335</td>\n",
       "      <td>India beat NZ 3-2 to enter CWG hockey finals</td>\n",
       "      <td>Afghanistan wins SAFF title, spoils India's ha...</td>\n",
       "      <td>AAP drops Rajouri Garden candidate, a week bef...</td>\n",
       "      <td>Kashmir's famous Dal Lake freezes</td>\n",
       "      <td>Indian Navy gets VLF, easy communication with ...</td>\n",
       "      <td>Bharti Airtel rakes in 61% profit</td>\n",
       "      <td>India's first Billiards Premier League</td>\n",
       "      <td>Infosys Gifts Sikka Shares Worth Rs 8.2cr</td>\n",
       "      <td>...</td>\n",
       "      <td>TVS Motor beats Hero MotoCorp to become 6th mo...</td>\n",
       "      <td>Car rental startup Zoomcar may go public via S...</td>\n",
       "      <td>Passenger vehicle wholesales rise by 92% in Se...</td>\n",
       "      <td>UP govt announces new EV policy to attract ₹30...</td>\n",
       "      <td>Amazon-backed Rivian's shares fall 9% after it...</td>\n",
       "      <td>Vintage cars on display to promote wildlife pr...</td>\n",
       "      <td>Vehicle registrations during festivals doubled...</td>\n",
       "      <td>Honda Motor, LG to build $4.4 billion EV batte...</td>\n",
       "      <td>Mercedes-Benz sees 28% rise in sales in India ...</td>\n",
       "      <td>K'taka HC allows cab aggregators to operate au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>india</td>\n",
       "      <td>...</td>\n",
       "      <td>automobile</td>\n",
       "      <td>automobile</td>\n",
       "      <td>automobile</td>\n",
       "      <td>automobile</td>\n",
       "      <td>automobile</td>\n",
       "      <td>automobile</td>\n",
       "      <td>automobile</td>\n",
       "      <td>automobile</td>\n",
       "      <td>automobile</td>\n",
       "      <td>automobile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_org</th>\n",
       "      <td>India may move up after Nigerian weightlifter ...</td>\n",
       "      <td>Samsung has unveiled the Galaxy start 2 Plus s...</td>\n",
       "      <td>In the CWG men's hockey semi-final against New...</td>\n",
       "      <td>Afghanistan won their maiden-SAFF Football Cha...</td>\n",
       "      <td>Only a week before Delhi Assembly polls, Aam A...</td>\n",
       "      <td>After the recent snowfall in upper reaches of ...</td>\n",
       "      <td>The Indian navy has a new communication system...</td>\n",
       "      <td>Bharti Airtel, India's top telecommunications ...</td>\n",
       "      <td>The Billiards and Snooker Association of Mahar...</td>\n",
       "      <td>In a regulatory filing to the BSE on Friday, I...</td>\n",
       "      <td>...</td>\n",
       "      <td>TVS Motor Company Limited has become the sixth...</td>\n",
       "      <td>Bengaluru-based car rental startup Zoomcar has...</td>\n",
       "      <td>Passenger vehicle wholesales in India surged b...</td>\n",
       "      <td>The Uttar Pradesh government announced a new e...</td>\n",
       "      <td>Amazon-backed EV-maker Rivian on Friday recall...</td>\n",
       "      <td>To create awareness about wildlife week, the K...</td>\n",
       "      <td>Vehicle registrations more than doubled in thi...</td>\n",
       "      <td>Honda Motor and LG Energy Solution on Tuesday ...</td>\n",
       "      <td>Mercedes-Benz India has registered 28% rise in...</td>\n",
       "      <td>The Karnataka High Court has allowed app-based...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_cleaned</th>\n",
       "      <td>india may move up after nigerian weightlifter ...</td>\n",
       "      <td>samsung has unveiled the galaxy start 2 plus s...</td>\n",
       "      <td>in the cwg men's hockey semifinal against new ...</td>\n",
       "      <td>afghanistan won their maidensaff football cham...</td>\n",
       "      <td>only a week before delhi assembly polls aam aa...</td>\n",
       "      <td>after the recent snowfall in upper reaches of ...</td>\n",
       "      <td>the indian navy has a new communication system...</td>\n",
       "      <td>bharti airtel india's top telecommunications c...</td>\n",
       "      <td>the billiards and snooker association of mahar...</td>\n",
       "      <td>in a regulatory filing to the bse on friday in...</td>\n",
       "      <td>...</td>\n",
       "      <td>tvs motor company limited has become the sixth...</td>\n",
       "      <td>bengalurubased car rental startup zoomcar has ...</td>\n",
       "      <td>passenger vehicle wholesales in india surged b...</td>\n",
       "      <td>the uttar pradesh government announced a new e...</td>\n",
       "      <td>amazonbacked evmaker rivian on friday recalled...</td>\n",
       "      <td>to create awareness about wildlife week the ka...</td>\n",
       "      <td>vehicle registrations more than doubled in thi...</td>\n",
       "      <td>honda motor and lg energy solution on tuesday ...</td>\n",
       "      <td>mercedesbenz india has registered 28 rise in s...</td>\n",
       "      <td>the karnataka high court has allowed appbased ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_lemmatized</th>\n",
       "      <td>india may move nigerian weightlifter chika ama...</td>\n",
       "      <td>samsung unveiled galaxy start 2 plus smartphon...</td>\n",
       "      <td>cwg men hockey semifinal new zealand saturday ...</td>\n",
       "      <td>afghanistan maidensaff football championship d...</td>\n",
       "      <td>week delhi assembly polls aam aadmi party tues...</td>\n",
       "      <td>recent snowfall upper reaches kashmir himalaya...</td>\n",
       "      <td>indian navy new communication system critical ...</td>\n",
       "      <td>bharti airtel india top telecommunications com...</td>\n",
       "      <td>billiards snooker association maharashtrabsam ...</td>\n",
       "      <td>regulatory filing bse friday infosys ltd decid...</td>\n",
       "      <td>...</td>\n",
       "      <td>tvs motor company limited become sixth mostval...</td>\n",
       "      <td>bengalurubased car rental startup zoomcar repo...</td>\n",
       "      <td>passenger vehicle wholesales india surged 92 3...</td>\n",
       "      <td>uttar pradesh government announced new electri...</td>\n",
       "      <td>amazonbacked evmaker rivian friday recalled ne...</td>\n",
       "      <td>create awareness wildlife week karnataka fores...</td>\n",
       "      <td>vehicle registrations doubled year navratri du...</td>\n",
       "      <td>honda motor lg energy solution tuesday said bu...</td>\n",
       "      <td>mercedesbenz india registered 28 rise sales 11...</td>\n",
       "      <td>karnataka high court allowed appbased cab aggr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>body_stemmed</th>\n",
       "      <td>india may move nigerian weightlifter chika ama...</td>\n",
       "      <td>samsung unveiled galaxy start 2 plus smartphon...</td>\n",
       "      <td>cwg men hockey semifinal new zealand saturday ...</td>\n",
       "      <td>afghanistan maidensaff football championship d...</td>\n",
       "      <td>week delhi assembly polls aam aadmi party tues...</td>\n",
       "      <td>recent snowfall upper reaches kashmir himalaya...</td>\n",
       "      <td>indian navy new communication system critical ...</td>\n",
       "      <td>bharti airtel india top telecommunications com...</td>\n",
       "      <td>billiards snooker association maharashtrabsam ...</td>\n",
       "      <td>regulatory filing bse friday infosys ltd decid...</td>\n",
       "      <td>...</td>\n",
       "      <td>tvs motor company limited become sixth mostval...</td>\n",
       "      <td>bengalurubased car rental startup zoomcar repo...</td>\n",
       "      <td>passenger vehicle wholesales india surged 92 3...</td>\n",
       "      <td>uttar pradesh government announced new electri...</td>\n",
       "      <td>amazonbacked evmaker rivian friday recalled ne...</td>\n",
       "      <td>create awareness wildlife week karnataka fores...</td>\n",
       "      <td>vehicle registrations doubled year navratri du...</td>\n",
       "      <td>honda motor lg energy solution tuesday said bu...</td>\n",
       "      <td>mercedesbenz india registered 28 rise sales 11...</td>\n",
       "      <td>karnataka high court allowed appbased cab aggr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 285 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                               0    \\\n",
       "title            Nigerian weightlifter in dope net, India may gain   \n",
       "category                                                     india   \n",
       "body_org         India may move up after Nigerian weightlifter ...   \n",
       "body_cleaned     india may move up after nigerian weightlifter ...   \n",
       "body_lemmatized  india may move nigerian weightlifter chika ama...   \n",
       "body_stemmed     india may move nigerian weightlifter chika ama...   \n",
       "\n",
       "                                                               1    \\\n",
       "title              Samsung launches Galaxy Star 2 Plus at Rs.7,335   \n",
       "category                                                     india   \n",
       "body_org         Samsung has unveiled the Galaxy start 2 Plus s...   \n",
       "body_cleaned     samsung has unveiled the galaxy start 2 plus s...   \n",
       "body_lemmatized  samsung unveiled galaxy start 2 plus smartphon...   \n",
       "body_stemmed     samsung unveiled galaxy start 2 plus smartphon...   \n",
       "\n",
       "                                                               2    \\\n",
       "title                 India beat NZ 3-2 to enter CWG hockey finals   \n",
       "category                                                     india   \n",
       "body_org         In the CWG men's hockey semi-final against New...   \n",
       "body_cleaned     in the cwg men's hockey semifinal against new ...   \n",
       "body_lemmatized  cwg men hockey semifinal new zealand saturday ...   \n",
       "body_stemmed     cwg men hockey semifinal new zealand saturday ...   \n",
       "\n",
       "                                                               3    \\\n",
       "title            Afghanistan wins SAFF title, spoils India's ha...   \n",
       "category                                                     india   \n",
       "body_org         Afghanistan won their maiden-SAFF Football Cha...   \n",
       "body_cleaned     afghanistan won their maidensaff football cham...   \n",
       "body_lemmatized  afghanistan maidensaff football championship d...   \n",
       "body_stemmed     afghanistan maidensaff football championship d...   \n",
       "\n",
       "                                                               4    \\\n",
       "title            AAP drops Rajouri Garden candidate, a week bef...   \n",
       "category                                                     india   \n",
       "body_org         Only a week before Delhi Assembly polls, Aam A...   \n",
       "body_cleaned     only a week before delhi assembly polls aam aa...   \n",
       "body_lemmatized  week delhi assembly polls aam aadmi party tues...   \n",
       "body_stemmed     week delhi assembly polls aam aadmi party tues...   \n",
       "\n",
       "                                                               5    \\\n",
       "title                            Kashmir's famous Dal Lake freezes   \n",
       "category                                                     india   \n",
       "body_org         After the recent snowfall in upper reaches of ...   \n",
       "body_cleaned     after the recent snowfall in upper reaches of ...   \n",
       "body_lemmatized  recent snowfall upper reaches kashmir himalaya...   \n",
       "body_stemmed     recent snowfall upper reaches kashmir himalaya...   \n",
       "\n",
       "                                                               6    \\\n",
       "title            Indian Navy gets VLF, easy communication with ...   \n",
       "category                                                     india   \n",
       "body_org         The Indian navy has a new communication system...   \n",
       "body_cleaned     the indian navy has a new communication system...   \n",
       "body_lemmatized  indian navy new communication system critical ...   \n",
       "body_stemmed     indian navy new communication system critical ...   \n",
       "\n",
       "                                                               7    \\\n",
       "title                            Bharti Airtel rakes in 61% profit   \n",
       "category                                                     india   \n",
       "body_org         Bharti Airtel, India's top telecommunications ...   \n",
       "body_cleaned     bharti airtel india's top telecommunications c...   \n",
       "body_lemmatized  bharti airtel india top telecommunications com...   \n",
       "body_stemmed     bharti airtel india top telecommunications com...   \n",
       "\n",
       "                                                               8    \\\n",
       "title                       India's first Billiards Premier League   \n",
       "category                                                     india   \n",
       "body_org         The Billiards and Snooker Association of Mahar...   \n",
       "body_cleaned     the billiards and snooker association of mahar...   \n",
       "body_lemmatized  billiards snooker association maharashtrabsam ...   \n",
       "body_stemmed     billiards snooker association maharashtrabsam ...   \n",
       "\n",
       "                                                               9    ...  \\\n",
       "title                    Infosys Gifts Sikka Shares Worth Rs 8.2cr  ...   \n",
       "category                                                     india  ...   \n",
       "body_org         In a regulatory filing to the BSE on Friday, I...  ...   \n",
       "body_cleaned     in a regulatory filing to the bse on friday in...  ...   \n",
       "body_lemmatized  regulatory filing bse friday infosys ltd decid...  ...   \n",
       "body_stemmed     regulatory filing bse friday infosys ltd decid...  ...   \n",
       "\n",
       "                                                               275  \\\n",
       "title            TVS Motor beats Hero MotoCorp to become 6th mo...   \n",
       "category                                                automobile   \n",
       "body_org         TVS Motor Company Limited has become the sixth...   \n",
       "body_cleaned     tvs motor company limited has become the sixth...   \n",
       "body_lemmatized  tvs motor company limited become sixth mostval...   \n",
       "body_stemmed     tvs motor company limited become sixth mostval...   \n",
       "\n",
       "                                                               276  \\\n",
       "title            Car rental startup Zoomcar may go public via S...   \n",
       "category                                                automobile   \n",
       "body_org         Bengaluru-based car rental startup Zoomcar has...   \n",
       "body_cleaned     bengalurubased car rental startup zoomcar has ...   \n",
       "body_lemmatized  bengalurubased car rental startup zoomcar repo...   \n",
       "body_stemmed     bengalurubased car rental startup zoomcar repo...   \n",
       "\n",
       "                                                               277  \\\n",
       "title            Passenger vehicle wholesales rise by 92% in Se...   \n",
       "category                                                automobile   \n",
       "body_org         Passenger vehicle wholesales in India surged b...   \n",
       "body_cleaned     passenger vehicle wholesales in india surged b...   \n",
       "body_lemmatized  passenger vehicle wholesales india surged 92 3...   \n",
       "body_stemmed     passenger vehicle wholesales india surged 92 3...   \n",
       "\n",
       "                                                               278  \\\n",
       "title            UP govt announces new EV policy to attract ₹30...   \n",
       "category                                                automobile   \n",
       "body_org         The Uttar Pradesh government announced a new e...   \n",
       "body_cleaned     the uttar pradesh government announced a new e...   \n",
       "body_lemmatized  uttar pradesh government announced new electri...   \n",
       "body_stemmed     uttar pradesh government announced new electri...   \n",
       "\n",
       "                                                               279  \\\n",
       "title            Amazon-backed Rivian's shares fall 9% after it...   \n",
       "category                                                automobile   \n",
       "body_org         Amazon-backed EV-maker Rivian on Friday recall...   \n",
       "body_cleaned     amazonbacked evmaker rivian on friday recalled...   \n",
       "body_lemmatized  amazonbacked evmaker rivian friday recalled ne...   \n",
       "body_stemmed     amazonbacked evmaker rivian friday recalled ne...   \n",
       "\n",
       "                                                               280  \\\n",
       "title            Vintage cars on display to promote wildlife pr...   \n",
       "category                                                automobile   \n",
       "body_org         To create awareness about wildlife week, the K...   \n",
       "body_cleaned     to create awareness about wildlife week the ka...   \n",
       "body_lemmatized  create awareness wildlife week karnataka fores...   \n",
       "body_stemmed     create awareness wildlife week karnataka fores...   \n",
       "\n",
       "                                                               281  \\\n",
       "title            Vehicle registrations during festivals doubled...   \n",
       "category                                                automobile   \n",
       "body_org         Vehicle registrations more than doubled in thi...   \n",
       "body_cleaned     vehicle registrations more than doubled in thi...   \n",
       "body_lemmatized  vehicle registrations doubled year navratri du...   \n",
       "body_stemmed     vehicle registrations doubled year navratri du...   \n",
       "\n",
       "                                                               282  \\\n",
       "title            Honda Motor, LG to build $4.4 billion EV batte...   \n",
       "category                                                automobile   \n",
       "body_org         Honda Motor and LG Energy Solution on Tuesday ...   \n",
       "body_cleaned     honda motor and lg energy solution on tuesday ...   \n",
       "body_lemmatized  honda motor lg energy solution tuesday said bu...   \n",
       "body_stemmed     honda motor lg energy solution tuesday said bu...   \n",
       "\n",
       "                                                               283  \\\n",
       "title            Mercedes-Benz sees 28% rise in sales in India ...   \n",
       "category                                                automobile   \n",
       "body_org         Mercedes-Benz India has registered 28% rise in...   \n",
       "body_cleaned     mercedesbenz india has registered 28 rise in s...   \n",
       "body_lemmatized  mercedesbenz india registered 28 rise sales 11...   \n",
       "body_stemmed     mercedesbenz india registered 28 rise sales 11...   \n",
       "\n",
       "                                                               284  \n",
       "title            K'taka HC allows cab aggregators to operate au...  \n",
       "category                                                automobile  \n",
       "body_org         The Karnataka High Court has allowed app-based...  \n",
       "body_cleaned     the karnataka high court has allowed appbased ...  \n",
       "body_lemmatized  karnataka high court allowed appbased cab aggr...  \n",
       "body_stemmed     karnataka high court allowed appbased cab aggr...  \n",
       "\n",
       "[6 rows x 285 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_df=dictlist_super_NLP_comp(all_articles,regexfilter=r'[^a-z0-9\\'\\s]',stop_words_extend_reduce=[\"'\"],interestingkeys=['body']);news_df.T\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercises\n",
    "\n",
    "The end result of this exercise should be a file named prepare.py that defines the requested functions.\n",
    "\n",
    "In this exercise we will be defining some functions to prepare textual data. These functions should apply equally well to both the codeup blog articles and the news articles that were previously acquired.\n",
    "\n",
    "    Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "        Lowercase everything\n",
    "        Normalize unicode characters\n",
    "        Replace anything that is not a letter, number, whitespace or a single quote.\n",
    "\n",
    "    Define a function named tokenize. It should take in a string and tokenize all the words in the string.\n",
    "\n",
    "    Define a function named stem. It should accept some text and return the text after applying stemming to all the words.\n",
    "\n",
    "    Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word.\n",
    "\n",
    "    Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords.\n",
    "\n",
    "    This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove.\n",
    "\n",
    "    Use your data from the acquire to produce a dataframe of the news articles. Name the dataframe news_df.\n",
    "\n",
    "    Make another dataframe for the Codeup blog posts. Name the dataframe codeup_df.\n",
    "\n",
    "    For each dataframe, produce the following columns:\n",
    "        title to hold the title\n",
    "        original to hold the original article/post content\n",
    "        clean to hold the normalized and tokenized original with the stopwords removed.\n",
    "        stemmed to hold the stemmed version of the cleaned data.\n",
    "        lemmatized to hold the lemmatized version of the cleaned data.\n",
    "\n",
    "    Ask yourself:\n",
    "        If your corpus is 493KB, would you prefer to use stemmed or lemmatized text?\n",
    "        lemmatized\n",
    "        \n",
    "        If your corpus is 25MB, would you prefer to use stemmed or lemmatized text?\n",
    "        lemmatized\n",
    "\n",
    "        If your corpus is 200TB of text and you're charged by the megabyte for your hosted computational resources, would you prefer to use stemmed or lemmatized text?\n",
    "        Stemmed unless the value added was greater enoungh to be account for the additional costs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datadf=pd.read_json('data.json')\n",
    "\n",
    "len(datadf)\n",
    "\n",
    "df_C=datadf[datadf['language']=='C'];df_C.head(n=30)\n",
    "\n",
    "\n",
    "df_Python=datadf[datadf['language']=='Python'];df_Python.head(n=30)\n",
    "\n",
    "\n",
    "df_Java=datadf[datadf['language']=='Java'];df_Java.head(n=30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "all_articles=(datadf['readme_contents']).to_dict()\n",
    "all_articles.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dictlist_super_NLP_comp(dictlist,regexfilter=r'[^a-z0-9\\'\\s]',stop_words_extend_reduce=[\"'\"]):\n",
    "    ''\n",
    "    ndictlist=deepcopy(dictlist)\n",
    "    mapper=[]\n",
    "    interestingkeys=list(ndictlist.keys())\n",
    "    for i in range(0,len(ndictlist)):           \n",
    "            k=interestingkeys[i]\n",
    "            text=ndictlist.get(k)         \n",
    "            org={f'org':text}\n",
    "            clean=basic_clean(text,regexfilter=regexfilter)\n",
    "            cleaned=({f'cleaned':clean})\n",
    "            lemmatized=lemmatizor(text,regexfilter)\n",
    "            stopfilteredlemitezed=stopfilter(lemmatized,stop_words_extend_reduce=stop_words_extend_reduce)\n",
    "            lemma={f'lemmatized':stopfilteredlemitezed}\n",
    "            stem=stemmed(text,regexfilter)\n",
    "            stopfilteredstem=stopfilter(stem,stop_words_extend_reduce=stop_words_extend_reduce)\n",
    "            stemma={f'stemmed':stopfilteredstem}\n",
    "            mapper.append({k:dict(**org,**cleaned,**lemma,**stemma)})\n",
    "\n",
    "    \n",
    " \n",
    "                \n",
    "               \n",
    "\n",
    "\n",
    "  \n",
    "       \n",
    "    return mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf=dictlist_super_NLP_comp(all_articles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a=pd.DataFrame(newdf[0]).T\n",
    "for i in range(1,len(newdf)):\n",
    "    b=pd.DataFrame(newdf[i]).T\n",
    "    a=pd.merge(a,b,how='outer',right_index=False,left_index=False)\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>org</th>\n",
       "      <th>stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cstack/db_tutorial</td>\n",
       "      <td>C</td>\n",
       "      <td># Let's Build a Simple Database\\n\\n[View rende...</td>\n",
       "      <td>let's build a simple database\\n\\nview rendere...</td>\n",
       "      <td>let build simple database view rendered tutori...</td>\n",
       "      <td># Let's Build a Simple Database\\n\\n[View rende...</td>\n",
       "      <td>let build simple database view rendered tutori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rui314/chibicc</td>\n",
       "      <td>C</td>\n",
       "      <td># chibicc: A Small C Compiler\\n\\n(The old mast...</td>\n",
       "      <td>chibicc a small c compiler\\n\\nthe old master ...</td>\n",
       "      <td>chibicc small c compiler old master moved hist...</td>\n",
       "      <td># chibicc: A Small C Compiler\\n\\n(The old mast...</td>\n",
       "      <td>chibicc small c compiler old master moved hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nelhage/reptyr</td>\n",
       "      <td>C</td>\n",
       "      <td>reptyr - A tool for \"re-ptying\" programs.\\n===...</td>\n",
       "      <td>reptyr  a tool for reptying programs\\n\\n\\nrept...</td>\n",
       "      <td>reptyr tool reptying programs reptyr utility t...</td>\n",
       "      <td>reptyr - A tool for \"re-ptying\" programs.\\n===...</td>\n",
       "      <td>reptyr tool reptying programs reptyr utility t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EyalAr/lwip</td>\n",
       "      <td>C</td>\n",
       "      <td>[![Version](http://img.shields.io/npm/v/lwip.s...</td>\n",
       "      <td>versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...</td>\n",
       "      <td>versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...</td>\n",
       "      <td>[![Version](http://img.shields.io/npm/v/lwip.s...</td>\n",
       "      <td>versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ibireme/yyjson</td>\n",
       "      <td>C</td>\n",
       "      <td>\\n# Introduction\\n\\n[![Build](https://flat.bad...</td>\n",
       "      <td>\\n introduction\\n\\nbuildhttpsflatbadgennetgith...</td>\n",
       "      <td>introduction buildhttpsflatbadgennetgithubstat...</td>\n",
       "      <td>\\n# Introduction\\n\\n[![Build](https://flat.bad...</td>\n",
       "      <td>introduction buildhttpsflatbadgennetgithubstat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 repo language  \\\n",
       "0  cstack/db_tutorial        C   \n",
       "1      rui314/chibicc        C   \n",
       "2      nelhage/reptyr        C   \n",
       "3         EyalAr/lwip        C   \n",
       "4      ibireme/yyjson        C   \n",
       "\n",
       "                                     readme_contents  \\\n",
       "0  # Let's Build a Simple Database\\n\\n[View rende...   \n",
       "1  # chibicc: A Small C Compiler\\n\\n(The old mast...   \n",
       "2  reptyr - A tool for \"re-ptying\" programs.\\n===...   \n",
       "3  [![Version](http://img.shields.io/npm/v/lwip.s...   \n",
       "4  \\n# Introduction\\n\\n[![Build](https://flat.bad...   \n",
       "\n",
       "                                             cleaned  \\\n",
       "0   let's build a simple database\\n\\nview rendere...   \n",
       "1   chibicc a small c compiler\\n\\nthe old master ...   \n",
       "2  reptyr  a tool for reptying programs\\n\\n\\nrept...   \n",
       "3  versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...   \n",
       "4  \\n introduction\\n\\nbuildhttpsflatbadgennetgith...   \n",
       "\n",
       "                                          lemmatized  \\\n",
       "0  let build simple database view rendered tutori...   \n",
       "1  chibicc small c compiler old master moved hist...   \n",
       "2  reptyr tool reptying programs reptyr utility t...   \n",
       "3  versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...   \n",
       "4  introduction buildhttpsflatbadgennetgithubstat...   \n",
       "\n",
       "                                                 org  \\\n",
       "0  # Let's Build a Simple Database\\n\\n[View rende...   \n",
       "1  # chibicc: A Small C Compiler\\n\\n(The old mast...   \n",
       "2  reptyr - A tool for \"re-ptying\" programs.\\n===...   \n",
       "3  [![Version](http://img.shields.io/npm/v/lwip.s...   \n",
       "4  \\n# Introduction\\n\\n[![Build](https://flat.bad...   \n",
       "\n",
       "                                             stemmed  \n",
       "0  let build simple database view rendered tutori...  \n",
       "1  chibicc small c compiler old master moved hist...  \n",
       "2  reptyr tool reptying programs reptyr utility t...  \n",
       "3  versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...  \n",
       "4  introduction buildhttpsflatbadgennetgithubstat...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>repo</th>\n",
       "      <th>language</th>\n",
       "      <th>readme_contents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cstack/db_tutorial</td>\n",
       "      <td>C</td>\n",
       "      <td># Let's Build a Simple Database\\n\\n[View rende...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rui314/chibicc</td>\n",
       "      <td>C</td>\n",
       "      <td># chibicc: A Small C Compiler\\n\\n(The old mast...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nelhage/reptyr</td>\n",
       "      <td>C</td>\n",
       "      <td>reptyr - A tool for \"re-ptying\" programs.\\n===...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EyalAr/lwip</td>\n",
       "      <td>C</td>\n",
       "      <td>[![Version](http://img.shields.io/npm/v/lwip.s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ibireme/yyjson</td>\n",
       "      <td>C</td>\n",
       "      <td>\\n# Introduction\\n\\n[![Build](https://flat.bad...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 repo language  \\\n",
       "0  cstack/db_tutorial        C   \n",
       "1      rui314/chibicc        C   \n",
       "2      nelhage/reptyr        C   \n",
       "3         EyalAr/lwip        C   \n",
       "4      ibireme/yyjson        C   \n",
       "\n",
       "                                     readme_contents  \n",
       "0  # Let's Build a Simple Database\\n\\n[View rende...  \n",
       "1  # chibicc: A Small C Compiler\\n\\n(The old mast...  \n",
       "2  reptyr - A tool for \"re-ptying\" programs.\\n===...  \n",
       "3  [![Version](http://img.shields.io/npm/v/lwip.s...  \n",
       "4  \\n# Introduction\\n\\n[![Build](https://flat.bad...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.merge(datadf,a,how='left',right_index=True,left_index=True)\n",
    "display(df.head(),datadf.head())## Verify merge\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadf=df #finish prepped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>repo</th>\n",
       "      <th>readme_contents</th>\n",
       "      <th>cleaned</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C</td>\n",
       "      <td>cstack/db_tutorial</td>\n",
       "      <td># Let's Build a Simple Database\\n\\n[View rende...</td>\n",
       "      <td>let's build a simple database\\n\\nview rendere...</td>\n",
       "      <td>let build simple database view rendered tutori...</td>\n",
       "      <td>let build simple database view rendered tutori...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>rui314/chibicc</td>\n",
       "      <td># chibicc: A Small C Compiler\\n\\n(The old mast...</td>\n",
       "      <td>chibicc a small c compiler\\n\\nthe old master ...</td>\n",
       "      <td>chibicc small c compiler old master moved hist...</td>\n",
       "      <td>chibicc small c compiler old master moved hist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C</td>\n",
       "      <td>nelhage/reptyr</td>\n",
       "      <td>reptyr - A tool for \"re-ptying\" programs.\\n===...</td>\n",
       "      <td>reptyr  a tool for reptying programs\\n\\n\\nrept...</td>\n",
       "      <td>reptyr tool reptying programs reptyr utility t...</td>\n",
       "      <td>reptyr tool reptying programs reptyr utility t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C</td>\n",
       "      <td>EyalAr/lwip</td>\n",
       "      <td>[![Version](http://img.shields.io/npm/v/lwip.s...</td>\n",
       "      <td>versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...</td>\n",
       "      <td>versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...</td>\n",
       "      <td>versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C</td>\n",
       "      <td>ibireme/yyjson</td>\n",
       "      <td>\\n# Introduction\\n\\n[![Build](https://flat.bad...</td>\n",
       "      <td>\\n introduction\\n\\nbuildhttpsflatbadgennetgith...</td>\n",
       "      <td>introduction buildhttpsflatbadgennetgithubstat...</td>\n",
       "      <td>introduction buildhttpsflatbadgennetgithubstat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>Java</td>\n",
       "      <td>Amterson/AlginProject</td>\n",
       "      <td>\\n### 1.非中文单词不够一行会自动截断，用符号“-”连接起来；\\n\\n### 2.适配...</td>\n",
       "      <td>\\n 1\\n\\n 2textviewandroidgravityandroidtextali...</td>\n",
       "      <td>1 2textviewandroidgravityandroidtextalignmentg...</td>\n",
       "      <td>1 2textviewandroidgravityandroidtextalignmentg...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>Java</td>\n",
       "      <td>twitch4j/twitch4j</td>\n",
       "      <td>&lt;p align=\"center\"&gt;&lt;a href=\"https://twitch4j.gi...</td>\n",
       "      <td>p aligncentera hrefhttpstwitch4jgithubioimg sr...</td>\n",
       "      <td>p aligncentera hrefhttpstwitch4jgithubioimg sr...</td>\n",
       "      <td>p aligncentera hrefhttpstwitch4jgithubioimg sr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>Java</td>\n",
       "      <td>ittianyu/POCenter</td>\n",
       "      <td>## 外包集中营 ##\\n\\n整合多个软件外包平台项目信息，替你筛选优质项目\\n\\n![MI...</td>\n",
       "      <td>\\n\\n\\n\\nmit licensehttpsimgshieldsiogithubli...</td>\n",
       "      <td>mit licensehttpsimgshieldsiogithublicensemasha...</td>\n",
       "      <td>mit licensehttpsimgshieldsiogithublicensemasha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Java</td>\n",
       "      <td>acloudyh/springCloud</td>\n",
       "      <td>## springCloud 学习\\n\\n[springCloud-config配置中心](...</td>\n",
       "      <td>springcloud \\n\\nspringcloudconfighttpsgithubc...</td>\n",
       "      <td>springcloud springcloudconfighttpsgithubcomacl...</td>\n",
       "      <td>springcloud springcloudconfighttpsgithubcomacl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>Java</td>\n",
       "      <td>baoyongzhang/ParcelableGenerator</td>\n",
       "      <td>ParcelableGenerator\\n===================\\n[ ![...</td>\n",
       "      <td>parcelablegenerator\\n\\n downloadhttpsapibintra...</td>\n",
       "      <td>parcelablegenerator downloadhttpsapibintraycom...</td>\n",
       "      <td>parcelablegenerator downloadhttpsapibintraycom...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>270 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    language                              repo  \\\n",
       "0          C                cstack/db_tutorial   \n",
       "1          C                    rui314/chibicc   \n",
       "2          C                    nelhage/reptyr   \n",
       "3          C                       EyalAr/lwip   \n",
       "4          C                    ibireme/yyjson   \n",
       "..       ...                               ...   \n",
       "265     Java             Amterson/AlginProject   \n",
       "266     Java                 twitch4j/twitch4j   \n",
       "267     Java                 ittianyu/POCenter   \n",
       "268     Java              acloudyh/springCloud   \n",
       "269     Java  baoyongzhang/ParcelableGenerator   \n",
       "\n",
       "                                       readme_contents  \\\n",
       "0    # Let's Build a Simple Database\\n\\n[View rende...   \n",
       "1    # chibicc: A Small C Compiler\\n\\n(The old mast...   \n",
       "2    reptyr - A tool for \"re-ptying\" programs.\\n===...   \n",
       "3    [![Version](http://img.shields.io/npm/v/lwip.s...   \n",
       "4    \\n# Introduction\\n\\n[![Build](https://flat.bad...   \n",
       "..                                                 ...   \n",
       "265  \\n### 1.非中文单词不够一行会自动截断，用符号“-”连接起来；\\n\\n### 2.适配...   \n",
       "266  <p align=\"center\"><a href=\"https://twitch4j.gi...   \n",
       "267  ## 外包集中营 ##\\n\\n整合多个软件外包平台项目信息，替你筛选优质项目\\n\\n![MI...   \n",
       "268  ## springCloud 学习\\n\\n[springCloud-config配置中心](...   \n",
       "269  ParcelableGenerator\\n===================\\n[ ![...   \n",
       "\n",
       "                                               cleaned  \\\n",
       "0     let's build a simple database\\n\\nview rendere...   \n",
       "1     chibicc a small c compiler\\n\\nthe old master ...   \n",
       "2    reptyr  a tool for reptying programs\\n\\n\\nrept...   \n",
       "3    versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...   \n",
       "4    \\n introduction\\n\\nbuildhttpsflatbadgennetgith...   \n",
       "..                                                 ...   \n",
       "265  \\n 1\\n\\n 2textviewandroidgravityandroidtextali...   \n",
       "266  p aligncentera hrefhttpstwitch4jgithubioimg sr...   \n",
       "267    \\n\\n\\n\\nmit licensehttpsimgshieldsiogithubli...   \n",
       "268   springcloud \\n\\nspringcloudconfighttpsgithubc...   \n",
       "269  parcelablegenerator\\n\\n downloadhttpsapibintra...   \n",
       "\n",
       "                                               stemmed  \\\n",
       "0    let build simple database view rendered tutori...   \n",
       "1    chibicc small c compiler old master moved hist...   \n",
       "2    reptyr tool reptying programs reptyr utility t...   \n",
       "3    versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...   \n",
       "4    introduction buildhttpsflatbadgennetgithubstat...   \n",
       "..                                                 ...   \n",
       "265  1 2textviewandroidgravityandroidtextalignmentg...   \n",
       "266  p aligncentera hrefhttpstwitch4jgithubioimg sr...   \n",
       "267  mit licensehttpsimgshieldsiogithublicensemasha...   \n",
       "268  springcloud springcloudconfighttpsgithubcomacl...   \n",
       "269  parcelablegenerator downloadhttpsapibintraycom...   \n",
       "\n",
       "                                            lemmatized  \n",
       "0    let build simple database view rendered tutori...  \n",
       "1    chibicc small c compiler old master moved hist...  \n",
       "2    reptyr tool reptying programs reptyr utility t...  \n",
       "3    versionhttpimgshieldsionpmvlwipsvghttpswwwnpmj...  \n",
       "4    introduction buildhttpsflatbadgennetgithubstat...  \n",
       "..                                                 ...  \n",
       "265  1 2textviewandroidgravityandroidtextalignmentg...  \n",
       "266  p aligncentera hrefhttpstwitch4jgithubioimg sr...  \n",
       "267  mit licensehttpsimgshieldsiogithublicensemasha...  \n",
       "268  springcloud springcloudconfighttpsgithubcomacl...  \n",
       "269  parcelablegenerator downloadhttpsapibintraycom...  \n",
       "\n",
       "[270 rows x 6 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reorder=['language',\n",
    "'repo',\n",
    " 'readme_contents',\n",
    " 'cleaned',\n",
    " 'stemmed',\n",
    " 'lemmatized']\n",
    "  \n",
    "datadf=datadf[reorder]\n",
    "\n",
    "\n",
    "datadf\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "38cca0c38332a56087b24af0bc80247f4fced29cb4f7f437d91dc159adec9c4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
